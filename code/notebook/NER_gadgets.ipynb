{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fd0678b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import string\n",
    "from nltk import word_tokenize, pos_tag\n",
    "import spacy\n",
    "import os\n",
    "import random\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
    "from ranker import TransformerRanker, CrossEncoderRanker, Classifier\n",
    "from preprocessor import *\n",
    "from mapper import Mapper\n",
    "from display_products import DisplayProducts\n",
    "import joblib\n",
    "from nltk.corpus import stopwords\n",
    "from pathlib import Path\n",
    "stop_words = stopwords.words('english')\n",
    "from spacy.training import Example\n",
    "from spacy.scorer import Scorer\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "046c91ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"/Users/chahaksethi/Desktop/Target/data/recipe1M_layers/layer1.json\"\n",
    "with open(filepath) as json_data:\n",
    "    recipe = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ef4abab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set input file directory\n",
    "\n",
    "# ip_file_dir = \"../Data/Target Data/\"\n",
    "ip_file_dir = \"/Users/chahaksethi/Desktop/Target/target/target_recipe_project/data/\"\n",
    "# Get grocery product hierarchy information\n",
    "group4 = pd.read_csv(os.path.join(ip_file_dir, \n",
    "                                   'group4_header.csv'),\n",
    "                      sep=',', \n",
    "                      low_memory=False)\n",
    "\n",
    "# Get scraped information for the above products\n",
    "products = pd.read_csv(os.path.join(ip_file_dir,\n",
    "                                    'scraped/products_group4.csv'))\n",
    "\n",
    "# Merge scraped information into the hierarchy table\n",
    "group4 = pd.merge(group4, products, \n",
    "                   how = 'left', on = 'tcin')\n",
    "\n",
    "# Preprocess the table\n",
    "group4 = preprocess_df(group4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "39cff466",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_indicator_regex = '(skillet|casserole|crockpot|steamer|ladle|dish|pot|sheet|tablespoon|processor|spoon|plate|whisk|griddle|mixer|grinder|bowl|oven|saucepan|foil|mortar|pestle|pitcher|bag|cup|blender|cooker|knife|glass|brush|colander|pan|fork)'\n",
    "method_indicator_regex = '(boil|boiling|bake|sliced|stir|beat|roast|roasted|fry|rinse|saute|drain|strain|sift|beat|chop|slice|sliced|grate|grill|cut)'\n",
    "\n",
    "def recipe_load(n):\n",
    "    recipe_instr=[]\n",
    "#     for i in range(s,n):\n",
    "    title = recipe[n]['title']\n",
    "    id = recipe[n]['id']\n",
    "        \n",
    "    for lis in recipe[n]['instructions']:\n",
    "        for key, val in lis.items():   \n",
    "            rem = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", val)\n",
    "            if rem !='':\n",
    "                recipe_instr.append(rem)\n",
    "    return ' '.join(recipe_instr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e65de0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dabcfc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created blank 'en' model\n"
     ]
    }
   ],
   "source": [
    "if model is not None:\n",
    "    nlp1 = spacy.load(model)  # load existing spaCy model\n",
    "    print(\"Loaded model '%s'\" % model)\n",
    "else:\n",
    "    nlp1 = spacy.blank('en')  # create blank Language class\n",
    "    print(\"Created blank 'en' model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf1074ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the built-in pipeline components and add them to the pipeline\n",
    "    # nlp.create_pipe works for built-ins that are registered with spaCy\n",
    "if 'ner' not in nlp1.pipe_names:\n",
    "    ner = nlp1.create_pipe('ner')\n",
    "    nlp1.add_pipe('ner', last=True)\n",
    "# otherwise, get it so we can add labels\n",
    "else:\n",
    "    ner = nlp1.get_pipe('ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a38133dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tools(recipe):\n",
    "    \"\"\"\n",
    "    looks for any and all cooking tools apparent in the instruction text by using the tool_indicator_regex\n",
    "    variable\n",
    "    \"\"\"\n",
    "    cooking_tools = []\n",
    "    start=[]\n",
    "    cooking_tool_ent=[]\n",
    "#     for word in set(instruction_words):\n",
    "    if len(re.findall(tool_indicator_regex, recipe, flags=re.I))>0:\n",
    "        match =  list(set(re.findall(tool_indicator_regex, recipe , flags=re.I)))\n",
    "        for word in match:\n",
    "#             print(word)\n",
    "            word_n = ' ' + word\n",
    "            recipe = recipe + ' '\n",
    "            for match in re.finditer(word_n, recipe, flags=re.I): #to find all occurences of a word in the recipe\n",
    "                if recipe[match.end()].isalpha()==False: #to remove the substrings like pan in panini\n",
    "                    cooking_tools.append((match.start()+1, match.end(), word))\n",
    "\n",
    "    \n",
    "    \n",
    "    matcher = Matcher(nlp.vocab)\n",
    "    pattern = [{\"LOWER\": \"dutch\"}, {\"LOWER\": \"oven\"}]\n",
    "    matcher.add(\"DutchOven\", [pattern])\n",
    "    pattern = [{\"LOWER\": \"electric\"}, {\"LOWER\": \"oven\"}]\n",
    "    matcher.add(\"ElectricOven\", [pattern])\n",
    "    pattern = [{\"LOWER\": \"electric\"}, {\"LOWER\": \"skillet\"}]\n",
    "    matcher.add(\"ElectricSkillet\", [pattern])\n",
    "    pattern = [{\"LOWER\": \"nonstick\"}, {\"LOWER\": \"skillet\"}]\n",
    "    matcher.add(\"NonstickSkillet\", [pattern])\n",
    "    pattern = [{\"LOWER\": \"nonstick\"}, {\"LOWER\": \"pan\"}]\n",
    "    matcher.add(\"NonstickPan\", [pattern])\n",
    "    pattern = [{\"LOWER\": \"muffin\"}, {\"LOWER\": \"liners\"}]\n",
    "    matcher.add(\"MuffinLiners\", [pattern])\n",
    "    pattern = [{\"LOWER\": \"parchment\"}, {\"LOWER\": \"paper\"}]\n",
    "    matcher.add(\"ParchmentPaper\", [pattern])\n",
    "    pattern = [{\"LOWER\": \"food\"}, {\"LOWER\": \"processor\"}]\n",
    "    matcher.add(\"ParchmentPaper\", [pattern])\n",
    "    pattern = [{\"LOWER\": \"loaf\"}, {\"LOWER\": \"pan\"}]\n",
    "    matcher.add(\"LoafPan\", [pattern])\n",
    "    pattern = [{\"LOWER\": \"loaf\"}, {\"LOWER\": \"pans\"}]\n",
    "    matcher.add(\"LoafPans\", [pattern])\n",
    "    pattern = [{\"LOWER\": \"baking\"}, {\"LOWER\": \"sheet\"}]\n",
    "    matcher.add(\"BakingSheet\", [pattern])\n",
    "    pattern = [{\"LOWER\": \"frying\"}, {\"LOWER\": \"pan\"}]\n",
    "    matcher.add(\"FryingPan\", [pattern])\n",
    "    pattern = [{\"LOWER\": \"electric\"}, {\"LOWER\": \"kettle\"}]\n",
    "    matcher.add(\"ElectricKettle\", [pattern])\n",
    "    doc = nlp(recipe)\n",
    "    matches = matcher(doc)\n",
    "    for match_id, start, end in matches:\n",
    "        string_id = nlp.vocab.strings[match_id]  # Get string representation\n",
    "        span = doc[start:end]  # The matched span\n",
    "        cooking_tools.append((span.start_char, span.end_char, span.text))\n",
    "    \n",
    "    for i in range(len(cooking_tools)):\n",
    "        c=0\n",
    "        for j in range(len(cooking_tools)):\n",
    "            if i!=j and cooking_tools[i][1]==cooking_tools[j][1]:\n",
    "                c+=1\n",
    "                if cooking_tools[i][0]<cooking_tools[j][0]: cooking_tool_ent.append((cooking_tools[i][0],cooking_tools[i][1], 'GADGET'))\n",
    "        if c==0:\n",
    "            cooking_tool_ent.append((cooking_tools[i][0],cooking_tools[i][1], 'GADGET'))\n",
    "    return cooking_tool_ent\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "00fb7544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find_tools(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dc3d8187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_tools(recipe):\n",
    "#     \"\"\"\n",
    "#     looks for any and all cooking tools apparent in the instruction text by using the tool_indicator_regex\n",
    "#     variable\n",
    "#     \"\"\"\n",
    "#     cooking_tools = []\n",
    "#     start=[]\n",
    "# #     for word in set(instruction_words):\n",
    "#     if len(re.findall(tool_indicator_regex, recipe, flags=re.I))>0:\n",
    "#         match =  list(set(re.findall(tool_indicator_regex, recipe , flags=re.I)))\n",
    "#         for word in match:\n",
    "# #             print(word)\n",
    "#             word_n = ' ' + word\n",
    "#             recipe = recipe + ' '\n",
    "#             for match in re.finditer(word_n, recipe, flags=re.I): #to find all occurences of a word in the recipe\n",
    "#                 if recipe[match.end()].isalpha()==False: #to remove the substrings like pan in panini\n",
    "#                     cooking_tools.append((match.start()+1, match.end(), word))\n",
    "# #             print(cooking_tools)\n",
    "#     cooking_tool_ent = [(i[0],i[1], 'GADGET') for i in cooking_tools]\n",
    "#     return cooking_tool_ent\n",
    "   \n",
    "def find_methods(recipe):\n",
    "    \"\"\"\n",
    "    looks for any and all cooking methods apparent in the instruction text by using the method_indicator_regex\n",
    "    variable\n",
    "    \"\"\"\n",
    "    cooking_methods = []\n",
    "    start=[]\n",
    "#         for word in set(instruction_words):\n",
    "    if len(re.findall(method_indicator_regex, recipe, flags=re.I))>0:\n",
    "        match =  list(set(re.findall(method_indicator_regex, recipe , flags=re.I)))\n",
    "        for word in match:\n",
    "            word_n = ' ' + word+' '\n",
    "            recipe = recipe + ' '\n",
    "            for match in re.finditer(word_n, recipe):\n",
    "                if recipe[match.end()-1].isalpha()==False:\n",
    "                    cooking_methods.append((match.start()+1, match.end()-1, word))\n",
    "#                 print(cooking_methods)\n",
    "    cooking_meth_ent = [(i[0],i[1], 'METHOD') for i in cooking_methods]\n",
    "    return cooking_meth_ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5e6ea94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = np.random.choice(len(recipe) , 500 , replace = False)\n",
    "n_valid = np.random.choice(len(recipe) , 100 , replace = False)\n",
    "data_train, data_valid=[], []\n",
    "reciple_in=[]\n",
    "for num, n in enumerate([n_train, n_valid]):\n",
    "    for i in n:\n",
    "        reciple_in.append(i)\n",
    "        recipe_loaded = recipe_load(i)\n",
    "        recipe_lower = recipe_loaded.lower()\n",
    "        recipe_trans = recipe_lower.replace('\\n', ' ')\n",
    "        recipe_trans = recipe_trans.replace(',', ' ')\n",
    "        recipe_trans = recipe_trans.replace('-', ' ')\n",
    "        recipe_trans = recipe_trans.replace('(', ' ')\n",
    "        recipe_trans = recipe_trans.replace(')', ' ')\n",
    "        recipe_trans = recipe_trans.replace('.', ' ')\n",
    "        recipe_trans = recipe_trans.replace('@', ' ')\n",
    "        recipe_trans = recipe_trans.replace(';', ' ')\n",
    "        cooking_tools = find_tools(recipe_trans)\n",
    "        cooking_methods = find_methods(recipe_trans)\n",
    "        cook = cooking_tools + cooking_methods\n",
    "        if num==0:\n",
    "            data_train.append((recipe_trans, {'entities': cook}))\n",
    "        else: \n",
    "            data_valid.append((recipe_trans, {'entities': cook}))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "78906bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_ents = ['GADGET','METHOD']\n",
    "\n",
    "for ent in add_ents:\n",
    "    ner.add_label(ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "364f75ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(ner_model, valid_data):\n",
    "    examples = []\n",
    "    scorer = Scorer()\n",
    "    for text, annotations in valid_data:\n",
    "        doc = ner_model.make_doc(text)\n",
    "        example = Example.from_dict(doc, annotations)\n",
    "        example.predicted = ner_model(str(example.predicted))\n",
    "        examples.append(example)\n",
    "    return scorer.score(examples)\n",
    "\n",
    "#  ents_p, the recall as ents_r and the F1 score as ents_f."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cb0ad8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a695ec7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  1  Loss:  {'ner': 2394.257412535428} Valid F1 score:  0.9738610903659447\n",
      "Iteration  2  Loss:  {'ner': 194.90777646193067} Valid F1 score:  0.994772218073189\n",
      "Iteration  3  Loss:  {'ner': 106.28244375321871} Valid F1 score:  0.9925705794947993\n",
      "Iteration  4  Loss:  {'ner': 93.13931543095876} Valid F1 score:  0.9947877885331348\n",
      "Iteration  5  Loss:  {'ner': 60.734136390351274} Valid F1 score:  0.9970193740685545\n",
      "Iteration  6  Loss:  {'ner': 75.94186795346273} Valid F1 score:  0.9962714392244595\n",
      "Final loss:  {'ner': 75.94186795346273}\n"
     ]
    }
   ],
   "source": [
    "# get names of other pipes to disable them during training\n",
    "n_iter = 6\n",
    "other_pipes = [pipe for pipe in nlp1.pipe_names if pipe != 'ner']\n",
    "with nlp1.disable_pipes(*other_pipes):  # only train NER\n",
    "    if model is None:\n",
    "        optimizer = nlp1.begin_training()\n",
    "    else:\n",
    "        optimizer = nlp1.resume_training()\n",
    "    for itn in range(n_iter):\n",
    "        random.shuffle(data_train)\n",
    "        losses = {}\n",
    "        for batch in spacy.util.minibatch(data_train, size=50):\n",
    "            for text, annotations in batch:\n",
    "                try:\n",
    "                    doc = nlp.make_doc(text)\n",
    "                    example = Example.from_dict(doc, annotations)\n",
    "                    nlp1.update(\n",
    "                        [example],\n",
    "                         drop = 0.25, # dropout \n",
    "                        sgd=optimizer,  # callable to update weights\n",
    "                        losses=losses)\n",
    "                except Exception as error:\n",
    "                    continue\n",
    "        eval_result = evaluate(nlp1, data_valid)\n",
    "        print(\"Iteration \",itn+1, \" Loss: \", losses, \"Valid F1 score: \", eval_result['ents_f'])\n",
    "print(\"Final loss: \", losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9917f5a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "85524b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to /Users/chahaksethi/Desktop/Target/models/NER_7\n"
     ]
    }
   ],
   "source": [
    "output_dir=Path(\"/Users/chahaksethi/Desktop/Target/models/NER_7\")\n",
    "\n",
    "if not output_dir.exists():\n",
    "        output_dir.mkdir()\n",
    "nlp1.to_disk(output_dir)\n",
    "print(\"Saved model to\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea68b4b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9a5164",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e841fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "34384beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skillet\n",
      "skillet\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(9, 13, 'GADGET'),\n",
       " (62, 66, 'GADGET'),\n",
       " (249, 253, 'GADGET'),\n",
       " (45, 52, 'GADGET'),\n",
       " (98, 105, 'GADGET'),\n",
       " (350, 357, 'GADGET')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 'heat the oven to 400f. cook bacon in a large skillet or dutch oven until crisp. remove bacon from skillet; reserve drippings. brown the chicken in hot bacon drippings, turning to brown all sides; drain. place chicken in a 2 1/2 to 3-quart casserole dish;sprinkle with bacon. combine onions, mushrooms, 2 tablespoons parsley, thyme and garlic in same skillet as before. cook over medium heat until thoroughly heated, stirring occasionally. stir in flour. gradually stir in wine. cook until mixture boils and thickens stirring constantly. pour over chicken and bacon in casserole. cover, bake at 400f for 40-50 minutes or until the chicken is fork tender and juices run clear. or if using a meat thermometer chicken is done when it holds at 180f for ten seconds. sprinkle with parsley.'\n",
    "print(a[98: 105])\n",
    "print(a[350: 357])\n",
    "a = a.replace('\\n', ' ')\n",
    "a = a.replace(',', ' ')\n",
    "a = a.replace('-', ' ')\n",
    "a = a.replace('(', ' ')\n",
    "a = a.replace(')', ' ')\n",
    "a = a.replace('.', ' ')\n",
    "a = a.replace('@', ' ')\n",
    "a = a.replace(';', ' ')\n",
    "a = a.lower()\n",
    "instruction_words = word_tokenize(a)\n",
    "ins_stop_wrds_rm = [word for word in instruction_words if word not in stop_words]\n",
    "find_tools(a)\n",
    "\n",
    "\n",
    "# b =\"Preheat oven to 325 degrees  You will need two muffin pans that hold 12 muffins each  Lightly spray with cooking spray  In a large mixing bowl  beat together the butter and sugar  Add the vanilla and eggs one at a time  beating well after each addition  Combine the flour and baking powder together in a bowl and add to the butter  sugar  and egg mixture  Mix on low speed until well blended the batter will be very thick  Divide the batter evenly among the 24 cups  This will fill them about half way  For the topping  mix together the flour  brown sugar  and cinnamon in a bowl  Add the hard butter and cut it in to the dry ingredients until it resembles coarse crumbs you can use your hands for this  rubbing it between your fingertips  Don't make it too fine  you want it to have some body to it  Note: I use my hand held pastry blender tool  Put about 1 tablespoon of the streusel topping over each cake using up all of the topping;you will not see much of the batter  Bake in a preheated oven on two shelves for about 18 minutes  switching shelves after the first 10 minutes  They are done when a toothpick inserted in the middle comes out clean  Do not overbake;start checking them at about 16 minutes  Cool 5 minutes in the pans then remove to a cooling rack \"\n",
    "# print(b[275:283])\n",
    "# print(b[219:228])\n",
    "# print(b[1159:1169])\n",
    "# print(b[973:979])\n",
    "\n",
    "# instruction_words = word_tokenize(b)\n",
    "# ins_stop_wrds_rm = [word for word in instruction_words if word not in stop_words]\n",
    "# find_methods(ins_stop_wrds_rm, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2bfd1b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4552378691801231685, 13, 15), (4552378691801231685, 154, 156)]\n",
      "<class 'spacy.tokens.span.Span'>\n",
      "4552378691801231685 DutchOven 13 15 56 66 dutch oven\n",
      "<class 'spacy.tokens.span.Span'>\n",
      "4552378691801231685 DutchOven 154 156 783 793 dutch oven\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{\"LOWER\": \"dutch\"}, {\"LOWER\": \"oven\"}]\n",
    "matcher.add(\"DutchOven\", [pattern])\n",
    "pattern = [{\"LOWER\": \"electric\"}, {\"LOWER\": \"oven\"}]\n",
    "matcher.add(\"ElectricOven\", [pattern])\n",
    "pattern = [{\"LOWER\": \"electric\"}, {\"LOWER\": \"skillet\"}]\n",
    "matcher.add(\"ElectricSkillet\", [pattern])\n",
    "pattern = [{\"LOWER\": \"nonstick\"}, {\"LOWER\": \"skillet\"}]\n",
    "matcher.add(\"NonstickSkillet\", [pattern])\n",
    "pattern = [{\"LOWER\": \"nonstick\"}, {\"LOWER\": \"pan\"}]\n",
    "matcher.add(\"NonstickPan\", [pattern])\n",
    "\n",
    "doc = nlp(a)\n",
    "matches = matcher(doc)\n",
    "for match_id, start, end in matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  # Get string representation\n",
    "    span = doc[start:end]  # The matched span\n",
    "    cooking_tools.append((span.start_char, span.end_char, span.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5388e40d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dutch oven'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[783:793]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5c1758",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
