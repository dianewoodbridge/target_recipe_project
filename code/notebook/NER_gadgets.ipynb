{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fd0678b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import string\n",
    "from nltk import word_tokenize, pos_tag\n",
    "import spacy\n",
    "import os\n",
    "import random\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
    "from ranker import TransformerRanker, CrossEncoderRanker, Classifier\n",
    "from preprocessor import *\n",
    "from mapper import Mapper\n",
    "from display_products import DisplayProducts\n",
    "import joblib\n",
    "from nltk.corpus import stopwords\n",
    "from pathlib import Path\n",
    "stop_words = stopwords.words('english')\n",
    "from spacy.training import Example\n",
    "from spacy.scorer import Scorer\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "046c91ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"/Users/chahaksethi/Desktop/Target/data/recipe1M_layers/layer1.json\"\n",
    "with open(filepath) as json_data:\n",
    "    recipe = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ef4abab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set input file directory\n",
    "\n",
    "# ip_file_dir = \"../Data/Target Data/\"\n",
    "ip_file_dir = \"/Users/chahaksethi/Desktop/Target/target/target_recipe_project/data/\"\n",
    "# Get grocery product hierarchy information\n",
    "group4 = pd.read_csv(os.path.join(ip_file_dir, \n",
    "                                   'group4_header.csv'),\n",
    "                      sep=',', \n",
    "                      low_memory=False)\n",
    "\n",
    "# Get scraped information for the above products\n",
    "products = pd.read_csv(os.path.join(ip_file_dir,\n",
    "                                    'scraped/products_group4.csv'))\n",
    "\n",
    "# Merge scraped information into the hierarchy table\n",
    "group4 = pd.merge(group4, products, \n",
    "                   how = 'left', on = 'tcin')\n",
    "\n",
    "# Preprocess the table\n",
    "group4 = preprocess_df(group4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "39cff466",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_indicator_regex = '(skillet|crockpot|steamer|ladle|dish|pot|sheet|processor|spoon|plate|whisk|griddle|mixer|grinder|bowl|oven|saucepan|foil|mortar|pestle|pitcher|bag|cup|blender|cooker|knife|glass|brush|colander|pan|fork)'\n",
    "method_indicator_regex = '(boil|bake|sliced|stir|roast|roasted|fry|rinse|drain|sift|beat|chop|slice|sliced|saute|grate|grill|cut)'\n",
    "\n",
    "def recipe_load(n):\n",
    "    recipe_instr=[]\n",
    "#     for i in range(s,n):\n",
    "    title = recipe[n]['title']\n",
    "    id = recipe[n]['id']\n",
    "        \n",
    "    for lis in recipe[n]['instructions']:\n",
    "        for key, val in lis.items():   \n",
    "            rem = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", val)\n",
    "            if rem !='':\n",
    "                recipe_instr.append(rem)\n",
    "    return ' '.join(recipe_instr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e65de0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8dabcfc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created blank 'en' model\n"
     ]
    }
   ],
   "source": [
    "if model is not None:\n",
    "    nlp1 = spacy.load(model)  # load existing spaCy model\n",
    "    print(\"Loaded model '%s'\" % model)\n",
    "else:\n",
    "    nlp1 = spacy.blank('en')  # create blank Language class\n",
    "    print(\"Created blank 'en' model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf1074ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the built-in pipeline components and add them to the pipeline\n",
    "    # nlp.create_pipe works for built-ins that are registered with spaCy\n",
    "if 'ner' not in nlp1.pipe_names:\n",
    "    ner = nlp1.create_pipe('ner')\n",
    "    nlp1.add_pipe('ner', last=True)\n",
    "# otherwise, get it so we can add labels\n",
    "else:\n",
    "    ner = nlp1.get_pipe('ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f533528a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tools(recipe):\n",
    "    \"\"\"\n",
    "    looks for any and all cooking tools apparent in the instruction text by using the tool_indicator_regex\n",
    "    variable\n",
    "    \"\"\"\n",
    "    cooking_tools = []\n",
    "    start=[]\n",
    "    cooking_tool_ent=[]\n",
    "#     for word in set(instruction_words):\n",
    "    if len(re.findall(tool_indicator_regex, recipe, flags=re.I))>0:\n",
    "        match =  list(set(re.findall(tool_indicator_regex, recipe , flags=re.I)))\n",
    "        for word in match:\n",
    "#             print(word)\n",
    "            word_n = ' ' + word\n",
    "            recipe = recipe + ' '\n",
    "            for match in re.finditer(word_n, recipe, flags=re.I): #to find all occurences of a word in the recipe\n",
    "                if recipe[match.end()].isalpha()==False: #to remove the substrings like pan in panini\n",
    "                    cooking_tools.append((match.start()+1, match.end(), word))\n",
    "\n",
    "    \n",
    "    \n",
    "    matcher = Matcher(nlp.vocab)\n",
    "    pattern = [{\"LOWER\": \"dutch\"}, {\"LOWER\": \"oven\"}]\n",
    "    matcher.add(\"DutchOven\", [pattern])\n",
    "    pattern = [{\"LOWER\": \"electric\"}, {\"LOWER\": \"oven\"}]\n",
    "    matcher.add(\"ElectricOven\", [pattern])\n",
    "    pattern = [{\"LOWER\": \"electric\"}, {\"LOWER\": \"skillet\"}]\n",
    "    matcher.add(\"ElectricSkillet\", [pattern])\n",
    "    pattern = [{\"LOWER\": \"nonstick\"}, {\"LOWER\": \"skillet\"}]\n",
    "    matcher.add(\"NonstickSkillet\", [pattern])\n",
    "    pattern = [{\"LOWER\": \"nonstick\"}, {\"LOWER\": \"pan\"}]\n",
    "    matcher.add(\"NonstickPan\", [pattern])\n",
    "    pattern = [{\"LOWER\": \"muffin\"}, {\"LOWER\": \"liners\"}]\n",
    "    matcher.add(\"MuffinLiners\", [pattern])\n",
    "    pattern = [{\"LOWER\": \"parchment\"}, {\"LOWER\": \"paper\"}]\n",
    "    matcher.add(\"ParchmentPaper\", [pattern])\n",
    "    pattern = [{\"LOWER\": \"food\"}, {\"LOWER\": \"processor\"}]\n",
    "    matcher.add(\"ParchmentPaper\", [pattern])\n",
    "    pattern = [{\"LOWER\": \"loaf\"}, {\"LOWER\": \"pan\"}]\n",
    "    matcher.add(\"LoafPan\", [pattern])\n",
    "    pattern = [{\"LOWER\": \"baking\"}, {\"LOWER\": \"sheet\"}]\n",
    "    matcher.add(\"BakingSheet\", [pattern])\n",
    "    doc = nlp(recipe)\n",
    "    matches = matcher(doc)\n",
    "    for match_id, start, end in matches:\n",
    "        string_id = nlp.vocab.strings[match_id]  # Get string representation\n",
    "        span = doc[start:end]  # The matched span\n",
    "        cooking_tools.append((span.start_char, span.end_char, span.text))\n",
    "    \n",
    "    for i in range(len(cooking_tools)):\n",
    "        c=0\n",
    "        for j in range(len(cooking_tools)):\n",
    "            if i!=j and cooking_tools[i][1]==cooking_tools[j][1]:\n",
    "                c+=1\n",
    "                if cooking_tools[i][0]<cooking_tools[j][0]: cooking_tool_ent.append((cooking_tools[i][0],cooking_tools[i][1], 'GADGET'))\n",
    "        if c==0:\n",
    "            cooking_tool_ent.append((cooking_tools[i][0],cooking_tools[i][1], 'GADGET'))\n",
    "    return cooking_tool_ent\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "faf2c676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find_tools(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "dc3d8187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_tools(recipe):\n",
    "#     \"\"\"\n",
    "#     looks for any and all cooking tools apparent in the instruction text by using the tool_indicator_regex\n",
    "#     variable\n",
    "#     \"\"\"\n",
    "#     cooking_tools = []\n",
    "#     start=[]\n",
    "# #     for word in set(instruction_words):\n",
    "#     if len(re.findall(tool_indicator_regex, recipe, flags=re.I))>0:\n",
    "#         match =  list(set(re.findall(tool_indicator_regex, recipe , flags=re.I)))\n",
    "#         for word in match:\n",
    "# #             print(word)\n",
    "#             word_n = ' ' + word\n",
    "#             recipe = recipe + ' '\n",
    "#             for match in re.finditer(word_n, recipe, flags=re.I): #to find all occurences of a word in the recipe\n",
    "#                 if recipe[match.end()].isalpha()==False: #to remove the substrings like pan in panini\n",
    "#                     cooking_tools.append((match.start()+1, match.end(), word))\n",
    "# #             print(cooking_tools)\n",
    "#     cooking_tool_ent = [(i[0],i[1], 'GADGET') for i in cooking_tools]\n",
    "#     return cooking_tool_ent\n",
    "   \n",
    "def find_methods(recipe):\n",
    "    \"\"\"\n",
    "    looks for any and all cooking methods apparent in the instruction text by using the method_indicator_regex\n",
    "    variable\n",
    "    \"\"\"\n",
    "    cooking_methods = []\n",
    "    start=[]\n",
    "#         for word in set(instruction_words):\n",
    "    if len(re.findall(method_indicator_regex, recipe, flags=re.I))>0:\n",
    "        match =  list(set(re.findall(method_indicator_regex, recipe , flags=re.I)))\n",
    "        for word in match:\n",
    "            word_n = ' ' + word+' '\n",
    "            recipe = recipe + ' '\n",
    "            for match in re.finditer(word_n, recipe):\n",
    "                if recipe[match.end()-1].isalpha()==False:\n",
    "                    cooking_methods.append((match.start()+1, match.end()-1, word))\n",
    "#                 print(cooking_methods)\n",
    "    cooking_meth_ent = [(i[0],i[1], 'METHOD') for i in cooking_methods]\n",
    "    return cooking_meth_ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5e6ea94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = np.random.choice(len(recipe) , 500 , replace = False)\n",
    "n_valid = np.random.choice(len(recipe) , 100 , replace = False)\n",
    "data_train, data_valid=[], []\n",
    "reciple_in=[]\n",
    "for num, n in enumerate([n_train, n_valid]):\n",
    "    for i in n:\n",
    "        reciple_in.append(i)\n",
    "        recipe_loaded = recipe_load(i)\n",
    "        recipe_lower = recipe_loaded.lower()\n",
    "        recipe_trans = recipe_lower.replace('\\n', ' ')\n",
    "        recipe_trans = recipe_trans.replace(',', ' ')\n",
    "        recipe_trans = recipe_trans.replace('-', ' ')\n",
    "        recipe_trans = recipe_trans.replace('(', ' ')\n",
    "        recipe_trans = recipe_trans.replace(')', ' ')\n",
    "        recipe_trans = recipe_trans.replace('.', ' ')\n",
    "        recipe_trans = recipe_trans.replace('@', ' ')\n",
    "        recipe_trans = recipe_trans.replace(';', ' ')\n",
    "        cooking_tools = find_tools(recipe_trans)\n",
    "        cooking_methods = find_methods(recipe_trans)\n",
    "        cook = cooking_tools + cooking_methods\n",
    "        if num==0:\n",
    "            data_train.append((recipe_trans, {'entities': cook}))\n",
    "        else: \n",
    "            data_valid.append((recipe_trans, {'entities': cook}))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "78906bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_ents = ['GADGET','METHOD']\n",
    "\n",
    "for ent in add_ents:\n",
    "    ner.add_label(ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "364f75ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(ner_model, valid_data):\n",
    "    examples = []\n",
    "    scorer = Scorer()\n",
    "    for text, annotations in valid_data:\n",
    "        doc = ner_model.make_doc(text)\n",
    "        example = Example.from_dict(doc, annotations)\n",
    "        example.predicted = ner_model(str(example.predicted))\n",
    "        examples.append(example)\n",
    "    return scorer.score(examples)\n",
    "\n",
    "#  ents_p, the recall as ents_r and the F1 score as ents_f."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "115b1257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a695ec7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chahaksethi/opt/anaconda3/lib/python3.8/site-packages/spacy/training/iob_utils.py:141: UserWarning: [W030] Some entities could not be aligned in the text \"put the walnuts in a food processor or a blender a...\" with entities \"[(228, 232, 'GADGET'), (352, 356, 'GADGET'), (41, ...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  1  Loss:  {'ner': 2266.0949205826237} Valid F1 score:  0.9867647058823529\n",
      "Iteration  2  Loss:  {'ner': 187.52720733353257} Valid F1 score:  0.9934065934065934\n",
      "Iteration  3  Loss:  {'ner': 93.28898956279922} Valid F1 score:  0.9934162399414775\n",
      "Iteration  4  Loss:  {'ner': 82.24084419213249} Valid F1 score:  0.9934545454545454\n",
      "Iteration  5  Loss:  {'ner': 83.18072966500152} Valid F1 score:  0.9934450109249818\n",
      "Final loss:  {'ner': 83.18072966500152}\n"
     ]
    }
   ],
   "source": [
    "# get names of other pipes to disable them during training\n",
    "n_iter = 5\n",
    "other_pipes = [pipe for pipe in nlp1.pipe_names if pipe != 'ner']\n",
    "with nlp1.disable_pipes(*other_pipes):  # only train NER\n",
    "    if model is None:\n",
    "        optimizer = nlp1.begin_training()\n",
    "    else:\n",
    "        optimizer = nlp1.resume_training()\n",
    "    for itn in range(n_iter):\n",
    "        random.shuffle(data_train)\n",
    "        losses = {}\n",
    "        for batch in spacy.util.minibatch(data_train, size=50):\n",
    "            for text, annotations in batch:\n",
    "                try:\n",
    "                    doc = nlp.make_doc(text)\n",
    "                    example = Example.from_dict(doc, annotations)\n",
    "                    nlp1.update(\n",
    "                        [example],\n",
    "                         drop = 0.25, # dropout \n",
    "                        sgd=optimizer,  # callable to update weights\n",
    "                        losses=losses)\n",
    "                except Exception as error:\n",
    "                    continue\n",
    "        eval_result = evaluate(nlp1, data_valid)\n",
    "        print(\"Iteration \",itn+1, \" Loss: \", losses, \"Valid F1 score: \", eval_result['ents_f'])\n",
    "print(\"Final loss: \", losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9917f5a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "85524b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to /Users/chahaksethi/Desktop/Target/models/NER_5\n"
     ]
    }
   ],
   "source": [
    "output_dir=Path(\"/Users/chahaksethi/Desktop/Target/models/NER_5\")\n",
    "\n",
    "if not output_dir.exists():\n",
    "        output_dir.mkdir()\n",
    "nlp1.to_disk(output_dir)\n",
    "print(\"Saved model to\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea68b4b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9a5164",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e841fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "34384beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skillet\n",
      "skillet\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(9, 13, 'GADGET'),\n",
       " (62, 66, 'GADGET'),\n",
       " (249, 253, 'GADGET'),\n",
       " (45, 52, 'GADGET'),\n",
       " (98, 105, 'GADGET'),\n",
       " (350, 357, 'GADGET')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 'heat the oven to 400f. cook bacon in a large skillet or dutch oven until crisp. remove bacon from skillet; reserve drippings. brown the chicken in hot bacon drippings, turning to brown all sides; drain. place chicken in a 2 1/2 to 3-quart casserole dish;sprinkle with bacon. combine onions, mushrooms, 2 tablespoons parsley, thyme and garlic in same skillet as before. cook over medium heat until thoroughly heated, stirring occasionally. stir in flour. gradually stir in wine. cook until mixture boils and thickens stirring constantly. pour over chicken and bacon in casserole. cover, bake at 400f for 40-50 minutes or until the chicken is fork tender and juices run clear. or if using a meat thermometer chicken is done when it holds at 180f for ten seconds. sprinkle with parsley.'\n",
    "print(a[98: 105])\n",
    "print(a[350: 357])\n",
    "a = a.replace('\\n', ' ')\n",
    "a = a.replace(',', ' ')\n",
    "a = a.replace('-', ' ')\n",
    "a = a.replace('(', ' ')\n",
    "a = a.replace(')', ' ')\n",
    "a = a.replace('.', ' ')\n",
    "a = a.replace('@', ' ')\n",
    "a = a.replace(';', ' ')\n",
    "a = a.lower()\n",
    "instruction_words = word_tokenize(a)\n",
    "ins_stop_wrds_rm = [word for word in instruction_words if word not in stop_words]\n",
    "find_tools(a)\n",
    "\n",
    "\n",
    "# b =\"Preheat oven to 325 degrees  You will need two muffin pans that hold 12 muffins each  Lightly spray with cooking spray  In a large mixing bowl  beat together the butter and sugar  Add the vanilla and eggs one at a time  beating well after each addition  Combine the flour and baking powder together in a bowl and add to the butter  sugar  and egg mixture  Mix on low speed until well blended the batter will be very thick  Divide the batter evenly among the 24 cups  This will fill them about half way  For the topping  mix together the flour  brown sugar  and cinnamon in a bowl  Add the hard butter and cut it in to the dry ingredients until it resembles coarse crumbs you can use your hands for this  rubbing it between your fingertips  Don't make it too fine  you want it to have some body to it  Note: I use my hand held pastry blender tool  Put about 1 tablespoon of the streusel topping over each cake using up all of the topping;you will not see much of the batter  Bake in a preheated oven on two shelves for about 18 minutes  switching shelves after the first 10 minutes  They are done when a toothpick inserted in the middle comes out clean  Do not overbake;start checking them at about 16 minutes  Cool 5 minutes in the pans then remove to a cooling rack \"\n",
    "# print(b[275:283])\n",
    "# print(b[219:228])\n",
    "# print(b[1159:1169])\n",
    "# print(b[973:979])\n",
    "\n",
    "# instruction_words = word_tokenize(b)\n",
    "# ins_stop_wrds_rm = [word for word in instruction_words if word not in stop_words]\n",
    "# find_methods(ins_stop_wrds_rm, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2336b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b97fcad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yy\n"
     ]
    }
   ],
   "source": [
    "if re.search('skillet', 'pan is a girl. skillet', flags=re.I):\n",
    "    print(\"yy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "04b0bb0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for s in ['skillet','steamer','ladle','dish','pot','sheet','nonstick skillet' ]:\n",
    "    p = re.compile(s)\n",
    "    print(bool(p.fullmatch(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f20f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'rinse the tofu  then cut crosswise into 6 slices  put slices between several layers of paper towels and let drain while making the sauce  prep the seasonings for the sauce: peel the garlic cloves and the ginger  then quarter the ginger  turn on your food processor and drop the garlic and ginger through the feed tube  theyll be minced in no time  stop the machine and the black beans in a small sieve until the water runs clear  add them to the food processor and pulse until coarsely chopped  for the liquid portion of the sauce  stir together the water  soy sauce  sherry  maple syrup  vinegar  and the cornstarch until the cornstarch is evenly suspended  now youre ready to cook the sauce! generously film the bottom of a heavy 2 quart saucepan with the vegetable oil and heat over moderately high heat until hot but not smoking  stir fry the seasonings until fragrant  less than a minute  stir the cornstarch mixture and add it to the pan  whisk the sauce occasionally while bringing it to a boil and simmer 1 minute  then set the sauce aside while you fry the tofu  generously film the bottom of a 12 inch nonstick skillet with vegetable oil and heat over high heat until hot but not smoking  blot up any excess moisture on the tofu with a paper towel before laying in the skillet  fry the slices on all sides   turning them only when the undersides are golden and crisp  5 to 8 minutes total  give the tofu one last flip on a paper towel to sop up any stray oil and reheat the sauce  serve with rice and broccoli  pouring sauce over all '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7e550084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "# Add match ID \"orderintake\" with no callback and one pattern\n",
    "pattern = [{\"LOWER\": \"order\"}, {\"LOWER\": \"intake\"}]\n",
    "matcher.add(\"orderintake\", [pattern])\n",
    "\n",
    "doc = nlp(\"order intake is strong for Q4 intake\")\n",
    "matches = matcher(doc)\n",
    "print(len(matches)) #Number of times the bi-gram appears in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8d799b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4552378691801231685, 13, 15), (4552378691801231685, 154, 156)]\n",
      "<class 'spacy.tokens.span.Span'>\n",
      "4552378691801231685 DutchOven 13 15 56 66 dutch oven\n",
      "<class 'spacy.tokens.span.Span'>\n",
      "4552378691801231685 DutchOven 154 156 783 793 dutch oven\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{\"LOWER\": \"dutch\"}, {\"LOWER\": \"oven\"}]\n",
    "matcher.add(\"DutchOven\", [pattern])\n",
    "pattern = [{\"LOWER\": \"electric\"}, {\"LOWER\": \"oven\"}]\n",
    "matcher.add(\"ElectricOven\", [pattern])\n",
    "pattern = [{\"LOWER\": \"electric\"}, {\"LOWER\": \"skillet\"}]\n",
    "matcher.add(\"ElectricSkillet\", [pattern])\n",
    "pattern = [{\"LOWER\": \"nonstick\"}, {\"LOWER\": \"skillet\"}]\n",
    "matcher.add(\"NonstickSkillet\", [pattern])\n",
    "pattern = [{\"LOWER\": \"nonstick\"}, {\"LOWER\": \"pan\"}]\n",
    "matcher.add(\"NonstickPan\", [pattern])\n",
    "\n",
    "doc = nlp(a)\n",
    "matches = matcher(doc)\n",
    "for match_id, start, end in matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  # Get string representation\n",
    "    span = doc[start:end]  # The matched span\n",
    "    cooking_tools.append((span.start_char, span.end_char, span.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d4d2fa7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dutch oven'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[783:793]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58ecf67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
